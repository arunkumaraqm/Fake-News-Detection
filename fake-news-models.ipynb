{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('minconda3': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5254c8068ec6a28f28d7240547fe46da68ed71b29d175470102f3b8f29d4e88e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'kaggle-fn-dataset'\n",
    "path_real = os.path.join(path, 'True.csv')\n",
    "path_fake = os.path.join(path, 'Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['title', 'text', 'subject', 'date'], dtype='object'), 21417)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "realdf = pd.read_csv(path_real)\n",
    "realdf.columns, len(realdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "realdf['label'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['title', 'text', 'subject', 'date', 'label'], dtype='object'), 23481)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "fakedf = pd.read_csv(path_fake)\n",
    "fakedf['label'] = False\n",
    "fakedf.columns, len(fakedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['title', 'text', 'subject', 'date', 'label'], dtype='object'), 44898)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df = pd.concat([realdf, fakedf])\n",
    "df.columns, len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(33673, 11225)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "traindf, testdf = train_test_split(df)\n",
    "len(traindf), len(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=50)\n",
    "vectorizer.fit(traindf.text)\n",
    "xtrain = vectorizer.transform(traindf.text).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test accuracy 0.912249443207127\n"
     ]
    }
   ],
   "source": [
    "xtest = vectorizer.transform(testdf.text).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = traindf.label\n",
    "ytest = testdf.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_score(model, xtrain, ytrain, xtest, ytest):\n",
    "    model.fit(xtrain, ytrain)\n",
    "    train_score = model.score(xtrain, ytrain)\n",
    "    test_score = model.score(xtest, ytest)\n",
    "    print('For', model)\n",
    "    print('Train score: ', train_score)    \n",
    "    print('Test score: ', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For SVC(random_state=0)\nTrain score:  0.9230540789356457\nTest score:  0.917683741648107\n"
     ]
    }
   ],
   "source": [
    "sv_model = SVC(kernel='rbf', random_state=0)\n",
    "train_and_score(sv_model, xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For MultinomialNB()\nTrain score:  0.878300121759273\nTest score:  0.8769710467706013\n"
     ]
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "train_and_score(mnb_model, xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
