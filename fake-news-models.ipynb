{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') # for nltk's sentence tokenization within word_tokenize\n",
    "nltk.download('wordnet') # for nltk's sentence tokenization within word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  U.S. Secretary of State John F. Kerry said Mon...   \n",
       "1           1  It's primary day in New York and front-runners...   \n",
       "2           2  A Czech stockbroker who saved more than 650 Je...   \n",
       "3           3  Hillary Clinton and Donald Trump made some ina...   \n",
       "4           4  Iranian negotiators reportedly have made a las...   \n",
       "\n",
       "                                               title  label  \n",
       "0        Kerry to go to Paris in gesture of sympathy      1  \n",
       "1   The Battle of New York: Why This Primary Matters      1  \n",
       "2                  ‚ÄòBritain‚Äôs Schindler‚Äô Dies at 106      1  \n",
       "3  Fact check: Trump and Clinton at the 'commande...      1  \n",
       "4  Iran reportedly makes new push for uranium con...      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>title</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A Czech stockbroker who saved more than 650 Je...</td>\n      <td>‚ÄòBritain‚Äôs Schindler‚Äô Dies at 106</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Hillary Clinton and Donald Trump made some ina...</td>\n      <td>Fact check: Trump and Clinton at the 'commande...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Iranian negotiators reportedly have made a las...</td>\n      <td>Iran reportedly makes new push for uranium con...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "path = os.path.join('data-payames', 'data-payames.csv')\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with nan\n",
    "# but this retains the original df index for rows\n",
    "# so reset that index (axis is 0)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(0, drop=True, inplace=True) # there are 8 rows with only title and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\t\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\\x7f\\x80\\x81\\x82\\x83\\x84\\x85\\x86\\x8a\\x8b\\x8c\\x8f\\x91\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\x9b\\x9c\\x9d\\x9f\\xa0¬°¬¢¬£¬•¬ß¬®¬©¬™¬´\\xad¬Æ¬Ø¬∞¬±¬≤¬¥¬∂¬∑¬∏¬π¬∫¬ª¬º¬Ω¬æ¬ø√Ä√Å√Ç√Ñ√Ö√á√à√â√ç√é√ê√ë√ì√ñ√ó√ò√ö√ú√ü√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∑√∏√π√∫√ª√ºƒÅƒÇƒÉƒçƒèƒëƒüƒ´ƒ∞≈É≈Ñ≈ç≈ì≈ö≈ü≈†≈°≈§≈•≈∏≈π»ôÀöÀúÃÑŒùŒ¨ŒØŒ±Œ≤ŒµŒ∑ŒπŒ∫ŒªŒºŒΩŒøœÅœÖ–ì–≠–∞–±–≤–≥–∏–π–∫–ª–Ω–æ—Ä—Å—Ç—É—è◊ê◊ë◊í◊ì◊î◊ï◊ñ◊ó◊ò◊ô◊ö◊õ◊ú◊ù◊û◊ü◊†◊°◊¢◊£◊§◊•◊¶◊ß◊®◊©◊™ÿ°ÿ£ÿ•ÿßÿ®ÿ©ÿ™ÿ¨ÿ≠ÿØÿ∞ÿ±ÿ∂ÿπŸÅŸÇŸÑŸÖŸÜŸáŸàŸâŸä‡∏á‡∏¢‡∏£·∫ì·ªã\\u2002\\u2008\\u2009\\u200a\\u200b\\u200c\\u200e‚Äë‚Äì‚Äî‚Äï‚Äò‚Äô‚Äú‚Äù‚Ä†‚Ä°‚Ä¢‚Ä¶\\u202f‚Ä≤‚Ä≥‚Äπ‚Ä∫‚ÅÑ‚Ç¨‚Çπ‚Ñ¢‚Öî‚Üí‚á©‚ñ∫‚óè‚òï‚ò¢‚òÆ‚ô•‚ô¶‚úì‚úü‚ùñ‚ù¶\\uf022\\uf0b7\\uf0dd\\uf50d\\uf64c\\uf6a8Ô∏è\\ufeffÔøºüá∏üá∫üåçüéÉüíöüòÄüòÇüòâüòçüò≠üò≥üôÇüôÑüßÄ'"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "''.join(sorted(list(set(''.join([i for i in df.text]))))) # the set of all characters that appear over all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_junk_chars(text):\n",
    "    return ''.join(ch for ch in text if ch in 'abcdefghijklmnopqrstuvwxyz''ABCDEFGHIJKLMNOPQRSTUVWXYZ''0123456789'' .,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = custom_stop_words.union(set(remove_junk_chars(text) for text in custom_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text_ser: pd.Series):\n",
    "#     new_text_list = []\n",
    "#     for text in text_ser:\n",
    "#         text = remove_junk_chars(text)\n",
    "#         new_text_list.append(text)\n",
    "#     return pd.Series(new_text_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.title = clean_text(df.title)\n",
    "# df.text = clean_text(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19909, 14931, 4978)"
      ]
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "traindf, testdf = train_test_split(df)\n",
    "len(df), len(traindf), len(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = traindf.label\n",
    "ytest = testdf.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_score(model, xtrain, ytrain, xtest, ytest):\n",
    "    model.fit(xtrain, ytrain)\n",
    "    # train_score = model.score(xtrain, ytrain)\n",
    "    test_score = model.score(xtest, ytest)\n",
    "    print('For', model)\n",
    "    # print('Train score: ', train_score)    \n",
    "    print('Test score: ', test_score)\n",
    "    return test_score\n",
    "\n",
    "def train_and_score_title_and_text(model, xtrain, ytrain, xtest, ytest): # doesn't work right now\n",
    "    model.fit(xtrain.text, ytrain)\n",
    "    # train_score = model.score(xtrain, ytrain)\n",
    "    test_score = model.score(xtest, ytest)\n",
    "    print('For', model)\n",
    "    # print('Train score: ', train_score)    \n",
    "    print('Test score: ', test_score)\n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerAndStemmer(object):\n",
    "    stem = nltk.PorterStemmer().stem\n",
    "    def __call__(self, text):\n",
    "        return (self.stem(remove_junk_chars(itoken)) for itoken in nltk.word_tokenize(text)) # returning a generator is more efficient\n",
    "\n",
    "class TokenizerAndLancasterStemmer(object):\n",
    "    stem = nltk.LancasterStemmer().stem\n",
    "    def __call__(self, text):\n",
    "        return (self.stem(remove_junk_chars(itoken)) for itoken in nltk.word_tokenize(text))\n",
    "\n",
    "class TokenizerAndLemmatizer(object):\n",
    "    lemma = nltk.WordNetLemmatizer().lemmatize\n",
    "    def __call__(self, text):\n",
    "        return (self.lemma(remove_junk_chars(itoken)) for itoken in nltk.word_tokenize(text))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizations = {\n",
    "    'bow':          CountVectorizer,\n",
    "    'tfidf':        TfidfVectorizer,\n",
    "    'bigram':       lambda *args, **kwargs: CountVectorizer(ngram_range=(2, 2), *args, **kwargs),\n",
    "}\n",
    "normalizations = {\n",
    "    'stem':         TokenizerAndStemmer(),\n",
    "    'stemmer':      TokenizerAndStemmer(),\n",
    "    'porter':       TokenizerAndStemmer(),\n",
    "    'lanc':         TokenizerAndLancasterStemmer(),\n",
    "    'lem':          TokenizerAndLemmatizer(),\n",
    "    'lemmer':       TokenizerAndLemmatizer(),\n",
    "    'lemmatizer':   TokenizerAndLemmatizer(),\n",
    "    'default':      None,\n",
    "    'def':          None,\n",
    "}\n",
    "algorithms = {\n",
    "    'mnb':          MultinomialNB,\n",
    "    'svm':          SVC,\n",
    "}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(specification):\n",
    "    str_vectorization, str_max_features, str_normalization, str_algorithm = specification.split()\n",
    "    max_features = int(str_max_features)\n",
    "    vectorizer = vectorizations[str_vectorization](\n",
    "        stop_words=custom_stop_words,\n",
    "        tokenizer=normalizations[str_normalization],\n",
    "        max_features=max_features,\n",
    "    )\n",
    "    algomodel = algorithms[str_algorithm]()\n",
    "    return vectorizer, algomodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...})),\n                ('multinomialnb', MultinomialNB())])\nTest score:  0.8589795098433106\nCPU times: user 9.52 s, sys: 51.8 ms, total: 9.57 s\nWall time: 9.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bow 1000 default mnb'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .86\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...},\n                                 tokenizer=<__main__.TokenizerAndStemmer object at 0x7fdc24b85fd0>)),\n                ('multinomialnb', MultinomialNB())])\nTest score:  0.8479308959421454\nCPU times: user 4min 39s, sys: 239 ms, total: 4min 39s\nWall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bow 1000 porter mnb'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .85\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...},\n                                 tokenizer=<__main__.TokenizerAndLancasterStemmer object at 0x7fdc24b85820>)),\n                ('multinomialnb', MultinomialNB())])\nTest score:  0.836078746484532\nCPU times: user 4min 3s, sys: 247 ms, total: 4min 3s\nWall time: 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bow 1000 lanc mnb'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .84\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...},\n                                 tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>)),\n                ('multinomialnb', MultinomialNB())])\nTest score:  0.8686219365206911\nCPU times: user 2min 31s, sys: 287 ms, total: 2min 31s\nWall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bow 1000 lemmatizer mnb'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .87; finally an improvement!\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000, ngram_range=(2, 2),\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...})),\n                ('multinomialnb', MultinomialNB())])\nTest score:  0.8897147448774608\nCPU times: user 32.9 s, sys: 921 ms, total: 33.8 s\nWall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bigram 1000 default mnb'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .89\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('tfidfvectorizer',\n                 TfidfVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...})),\n                ('multinomialnb', MultinomialNB())])\nTest score:  0.8648051426275613\nCPU times: user 9.7 s, sys: 36 ms, total: 9.74 s\nWall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'tfidf 1000 default mnb'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .86\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...})),\n                ('svc', SVC())])\nTest score:  0.9152269987946967\nCPU times: user 2min 7s, sys: 396 ms, total: 2min 7s\nWall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bow 1000 default svm'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .91\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000, ngram_range=(2, 2),\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...},\n                                 tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>)),\n                ('multinomialnb', MultinomialNB())])\nTest score:  0.8748493370831659\nCPU times: user 2min 33s, sys: 420 ms, total: 2min 34s\nWall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bigram 1000 lemmatizer mnb'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .87\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('tfidfvectorizer',\n                 TfidfVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...},\n                                 tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>)),\n                ('multinomialnb', MultinomialNB())])\nTest score:  0.8623945359582161\nCPU times: user 2min 41s, sys: 31.7 ms, total: 2min 41s\nWall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'tfidf 1000 lemmatizer mnb'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .86\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...},\n                                 tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>)),\n                ('svc', SVC())])\nTest score:  0.8029329047810365\nCPU times: user 4min 6s, sys: 71.5 ms, total: 4min 6s\nWall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bow 1000 lemmatizer svm'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .80\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000, ngram_range=(2, 2),\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...},\n                                 tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>)),\n                ('svc', SVC())])\nTest score:  0.7870630775411812\nCPU times: user 3min 54s, sys: 752 ms, total: 3min 55s\nWall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bigram 1000 lemmatizer svm'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .79\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(max_features=1000, ngram_range=(2, 2),\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...})),\n                ('svc', SVC())])\nTest score:  0.8869023704298915\nCPU times: user 53.3 s, sys: 1 s, total: 54.3 s\nWall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'bigram 1000 default svm'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .89\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('tfidfvectorizer',\n                 TfidfVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...},\n                                 tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>)),\n                ('svc', SVC())])\nTest score:  0.9463640016070711\nCPU times: user 4min 2s, sys: 132 ms, total: 4min 2s\nWall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'tfidf 1000 lemmatizer svm'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .95\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Pipeline(steps=[('tfidfvectorizer',\n                 TfidfVectorizer(max_features=1000,\n                                 stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'arent', 'as',\n                                             'at', 'be', 'because', 'been',\n                                             'before', 'being', 'below',\n                                             'between', 'both', 'but', 'by',\n                                             'can', 'couldn', ...})),\n                ('svc', SVC())])\nTest score:  0.9357171554841301\nCPU times: user 2min 16s, sys: 168 ms, total: 2min 16s\nWall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'tfidf 1000 default svm'\n",
    "my_vectorizer, my_algomodel = decode(name)\n",
    "my_pipeline = make_pipeline(my_vectorizer, my_algomodel)\n",
    "test_score = train_and_score(my_pipeline, traindf.text, ytrain, testdf.text, ytest) # .93\n",
    "results[name] = (my_vectorizer, my_algomodel, test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import joblib\n",
    "fout = open('Results.txt', 'a')\n",
    "print(file=fout)\n",
    "for name, rest in results.items():\n",
    "    my_vectorizer, my_algomodel, test_score = rest\n",
    "    timenow = str(datetime.now())\n",
    "    print(name, timenow, test_score, sep='\\t', file=fout)\n",
    "    joblib.dump(make_pipeline(my_vectorizer, my_algomodel), f'{timenow} {name}.joblib')\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bow 1000 default mnb': (CountVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...}),\n",
       "  MultinomialNB(),\n",
       "  0.8589795098433106),\n",
       " 'bow 1000 porter mnb': (CountVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                  tokenizer=<__main__.TokenizerAndStemmer object at 0x7fdc24b85fd0>),\n",
       "  MultinomialNB(),\n",
       "  0.8479308959421454),\n",
       " 'tfidf 1000 default mnb': (TfidfVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...}),\n",
       "  MultinomialNB(),\n",
       "  0.8648051426275613),\n",
       " 'bow 1000 default svm': (CountVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...}),\n",
       "  SVC(),\n",
       "  0.9152269987946967),\n",
       " 'bow 1000 lanc mnb': (CountVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                  tokenizer=<__main__.TokenizerAndLancasterStemmer object at 0x7fdc24b85820>),\n",
       "  MultinomialNB(),\n",
       "  0.836078746484532),\n",
       " 'bigram 1000 default mnb': (CountVectorizer(max_features=1000, ngram_range=(2, 2),\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...}),\n",
       "  MultinomialNB(),\n",
       "  0.8897147448774608),\n",
       " 'bow 1000 lemmatizer mnb': (CountVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                  tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>),\n",
       "  MultinomialNB(),\n",
       "  0.8686219365206911),\n",
       " 'bigram 1000 lemmatizer mnb': (CountVectorizer(max_features=1000, ngram_range=(2, 2),\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                  tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>),\n",
       "  MultinomialNB(),\n",
       "  0.8748493370831659),\n",
       " 'bow 1000 lemmatizer svm': (CountVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                  tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>),\n",
       "  SVC(),\n",
       "  0.8029329047810365),\n",
       " 'tfidf 1000 lemmatizer mnb': (TfidfVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                  tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>),\n",
       "  MultinomialNB(),\n",
       "  0.8623945359582161),\n",
       " 'bigram 1000 lemmatizer svm': (CountVectorizer(max_features=1000, ngram_range=(2, 2),\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                  tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>),\n",
       "  SVC(),\n",
       "  0.7870630775411812),\n",
       " 'tfidf 1000 lemmatizer svm': (TfidfVectorizer(max_features=1000,\n",
       "                  stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                              'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                              'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                              'because', 'been', 'before', 'being', 'below',\n",
       "                              'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                  tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>),\n",
       "  SVC(),\n",
       "  0.9463640016070711)}"
      ]
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotFittedError",
     "evalue": "This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-883a718e26c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tfidf 1000 lemmatizer svm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0myproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0myproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/minconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/minconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/minconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             raise NotFittedError(\"predict_proba is not available when fitted \"\n",
      "\u001b[0;32m~/software/minconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/minconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/minconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# for name, rest in results:\n",
    "rest = results['tfidf 1000 lemmatizer svm']\n",
    "model = make_pipeline(rest[0], SVC(probability=True))\n",
    "yproba = model.predict_proba(testdf.text)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "auc = roc_auc_score(y_test, yproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=1000,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'arent', 'as', 'at', 'be',\n",
       "                            'because', 'been', 'before', 'being', 'below',\n",
       "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...},\n",
       "                tokenizer=<__main__.TokenizerAndLemmatizer object at 0x7fdc24b85130>)"
      ]
     },
     "metadata": {},
     "execution_count": 222
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}